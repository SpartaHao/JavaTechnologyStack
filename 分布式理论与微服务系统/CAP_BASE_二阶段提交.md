## 请简述一下CAP理论，我们常见的中间件分别侧重点是什么？简述一下BASE理论？Mysql 满足CAP中哪些？
**对于本地事务处理或者是集中式的事务处理系统（单机系统），一般采用ACID（原子性Atomicity、一致性Consistency、隔离性Isolation、持久性Duralibility）模型来保证数据的一致性**。
而对于**分布式系统，我们需要兼顾可用性和一致性**，如果要求系统具有严格一致性时，很可能就会牺牲系统的可用性，一般采用的是CAP理论和BASE理论.

原子性：事务的原子性是指事务必须是一个原子的操作序列单元。**事务中包含的各项操作在一次执行过程中，只允许出现两种状态：全部执行成功、全部不执行**。任何一项操作失败都将导致整个事务失败，
同时其他已经被执行的操作都将被撤销并回滚，只有所有的操作全部执行完成，整个事务才算是成功完成。

### CAP理论
**一个分布式系统不可能同时满足一致性（C：Consistency），可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的两项**。
**对于一个分布式系统而言，网络问题又是一个必定会出现的问题，分区容错性可以说是一个基本的需求，因此主要是根据业务特点在一致性和可用性之间寻找平衡**。

* **一致性：数据在多个副本之间是否能够保持一致的特性**。在分布式系统中，如果能够做到针对一个数据项的更新操作执行完成后，所有的用户都可以读取到最新的值，那么这样的系统就可以被认为具有**强一致性**；
如果允许之后部分或者全部感知不到该更新，称为**弱一致性**；若在之后的一段时间（通常该时间不固定）后，一定可以感知到该更新，称为**最终一致性**；
* 可用性：对于用户的每一个操作，**请求总是能够在有限的时间内返回结果**。
* 分区容错性：**分布式系统在遇到任何的网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务**，除非是整个网络环境都发生了故障。

### 常用中间件在CAP中的侧重点
CA：单点集群，满足一致性、可用性的系统，通常在可扩展性上不太强大。传统oracle数据库，kafka。  
CP：满足一致性、分区容错性的系统，通常性能不是特别高。单机版redis、MongoDB、zookeeper选择CP。  
AP：满足可用性、分区容纳广场性的系统，通常对一致性要求低一些。**集群版redis，大多数网站架构选择AP**。  

#### ZooKeeper是个CP的
任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性；ZooKeeper作为分布式协调服务，它的职责是保证数据（注：配置数据，状态数据）在其管辖下的所有服务之间保持同步、一致；
但是它**不能保证每次服务请求的可用性**（注：也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果，如leader选举的过程中）。  
作为ZooKeeper的核心实现算法 Zab ，就是解决了分布式系统下数据如何在多个服务之间保持同步问题的。进行leader选举时集群都是不可用。在使用ZooKeeper获取服务列表时，
当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪，
虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。所以说，ZooKeeper不能保证服务可用性。

https://blog.csdn.net/yanpenglei/article/details/80362561

#### kafka满足的是CAP理论当中的CA
Partition tolerance是通过一定的机制尽量满足。**kafka首先将数据写入到不同的分区里面去，每个分区又可能有好多个副本，数据首先写入到leader分区里面去，读写的操作都是与leader分区进行通信，
保证了数据的一致性原则，也就是满足了Consistency原则**。然后kafka通过分区副本机制，来保证了kafka当中数据的可用性。

但是也存在另外一个问题，就是副本分区当中的数据与leader当中的数据存在差别的问题如何解决，这个就是Partition tolerance的问题。kafka为了解决Partition tolerance的问题，
使用了**ISR的同步策略**，来尽最大可能减少Partition tolerance的问题。在leader分区中会维护一个ISR（a set of in-sync replicas，基本同步）列表，
ISR列表主要的作用就是决定哪些副本分区是可用的，也就是说可以将leader分区里面的数据同步到副本分区里面去，决定一个副本分区是否可用的条件有两个。  
*	 replica.lag.time.max.ms=10000     副本分区与主分区心跳时间延迟，多久没有向leader fetch消息了
*  replica.lag.max.messages=4000     副本分区与主分区消息同步最大差,新版本取消了  

这里的意思就是说如果某个follower分区超过最大延迟时间还没和leader进行心跳感知或者和leader分区的消息同步差值超过4000条，ISR就认为这个分区不可用了，就会把该分区从ISR中移除。同时ACK前需要保证有多少个备份。

#### 单机版的Redis属于保证CP(Consistency & Partition-Tolerancy)而牺牲A(Availability)
也就说Redis能够保证所有用户看到相同的数据（一致性，因为Redis不自动冗余数据）和网络通信出问题时，暂时隔离开的子系统能继续运行（分区容忍性，因为Master之间没有直接关系，不需要通信），
但是不保证某些结点故障时，所有请求都能被响应（可用性，某个Master结点挂了的话，那么它上面分片的数据就无法访问了）。

**有了Cluster功能后，Redis从一个单纯的NoSQL内存数据库变成了分布式NoSQL数据库，CAP模型也从CP变成了AP**。也就是说，通过自动分片和冗余数据，Redis具有了真正的分布式能力，某个结点挂了的话，
因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了Availability。然而，也正因为这一点，Redis无法保证曾经的强一致性了。这也是CAP理论要求的，三者只能取其二。

### BASE理论
BASE（**基本可用Basically Available、软状态Soft state、最终一致性Eventually consistent**）是基于CAP逐步演化而来的，不同于ACID的强一致性模型，其**核心思想是通过牺牲强一致性来获得可用性**，
即使无法做到强一致性，但每个应用可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。

* 基本可用：什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：  
**响应时间上的损失**：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。  
**功能上的损失**：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 

* 软状态什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。
软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即**允许系统在多个不同节点的数据副本存在数据延时**。
* 最终一致性：上面说软状态，然后不可能一直是软状态，必须有个时间期限。**在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性**。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。

而在实际工程实践中，最终一致性分为5种：
1. 因果一致性（Causal consistency）  
因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。
1. 读己之所写（Read your writes）  
读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。
1. 会话一致性（Session consistency）  
会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。
1. 单调读一致性（Monotonic read consistency）  
单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。
1. 单调写一致性（Monotonic write consistency）  
单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。

在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。而且不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。
比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。

## 二阶段提交
二阶段提交将一个事务的处理过程分为了**投票和执行两个阶段，其核心是对每个事务都采用先尝试后提交的处理方式**，如果失败，利用在阶段一中记录的Undo信息来执行事务Rollback，
因此也可以**将二阶段提交看做一个强一致性算法**。

### 第一阶段
1. 事务询问  
协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应
2. 执行事务  
各参与者节点执行事务操作，并将Undo和Redo信息记入事务日志;  
> **undo日志用于记录事务开始前的状态，用于事务失败时的回滚操作；redo日志记录事务执行后的状态**，用来恢复未写入data file的已成功事务更新的数据。
例如某一事务的事务序号为T1，其对数据X进行修改，设X的原值是5，修改后的值为15，那么Undo日志为<T1, X, 5>，Redo日志为<T1, X, 15>。
3. 各参与者向协调者反馈事务询问的响应  
如果参与者成功执行了事务操作，那么就反馈YES给协调者，表示事务可以执行；如果没有成功执行事务，则反馈No，表示事务不可以执行

### 第二阶段
#### 假如协调者从所有参与者得到的反馈都是YES，则执行事务提交：
1. 发送提交请求  
协调者向所有的参与者发送commit请求
2. 事务提交  
参与者收到commit请求后，会执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源
3. 反馈事务提交结果  
参与者在完成事务提交之后，向协调者发送Ack消息
4. 完成事务  
协调者接受到所有参与者反馈的Ack消息后，完成事务

#### 假如有参与者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，则会中断事务：
1. 发送回滚请求  
协调者向所有的参与者发送Rollback请求
2. 事务提交  
参与者收到Rollback请求后，会利用其在阶段一中记录的Undo信息来执行事务回滚操作，并清理占用的事务资源
3. 反馈事务回滚结果  
参与者在完成事务回滚之后，向协调者发送Ack消息
4. 中断事务  
协调者接受到所有参与者反馈的Ack消息后，完成事务中断

#### 二阶段提交优缺点
二阶段提交协议的优点：原理简单，实现方便

二阶段提交协议的缺点：
* **同步阻塞**：各个参与者在等待其他参与者响应的过程中，无法进行其他任何操作
* **单点问题**：协调者出现问题，整个二阶段提交流程将无法运转
* **脑裂**：若阶段二有部分参与者没有收到Commit请求，则整个分布式系统会出现数据不一致的现象
* **太过保守**：没有较为完善的容错机制，任意一个节点的失败都会导致整个事务的失败

## 三阶段提交
三阶段提交是2PC（Two-Phase Commit）的改进版，**将二阶段提交协议的“提交事务请求”过程一分为二，形成了由CanCommit（确认自身是否可以执行事务操作），PreCommit（执行事务操作）和doCommit（执行事务提交）三个阶段组成的事务处理协议**

### 为什么三阶段提交可以解决二阶段提交的无限期等待问题呢？
假设有协调者cor,参与者a,b,c。  
对于二阶段提交，假如第一阶段a回了NO，b和c回了YES，当第二阶段cor给a发完abort后挂了，然后a执行完后也挂了，这时b和c不知道最后的提案是什么，事务的状态的也是不确定，即使重新选出协调者也会数据不一致。反之，如果a回了YES，b和c有一个回了No也是一样的道理
对于三阶段提交，canpreCommit阶段挂了无所谓，因为没有执行事务；假如协调者在收到第一阶段参与者所有的响应后，

#待补充
