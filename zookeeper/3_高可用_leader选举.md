## 16. 如何保证Zookeeper 集群的高可用？
**三机房部署，无论哪个机房发生了故障，剩下两个机房的机器数量都超过半数**。在进行 ZooKeeper 的容灾方案设计过程中，我们要充分考虑到“过半原则”,
也就是说，**无论发生什么情况，我们必须保证 ZooKeeper 集群中有超过半数的机器能够正常工作**。

## 17. Zookeeper为什么建议是奇数台部署？
Zookeeper官方建议部署奇数台服务器，其实是**基于节约资源的角度来考虑**的。Zookeeper默认采用Quorums组件来处理集群的脑裂问题。Quorums的原则就是过半存活即可用。
Quorums是WARO(Write ALL Read One,当client请求向某副本写数据时，只有当所有副本都更新成功之后，这次写操作才算成功，否则视为失败)副本控制协议的折衷。奇数部署有下面两个优点：
* **发生网络分区的时候（两个）保证有一个分区一定是有大多数机器的**，保证zookeeper集群可以继续对外提供服务；
* **节约资源**。基于“过半”设计原则，只要ZooKeeper集群中超过半数的机器还能够正常工作，整个集群就能够对外提供服务。基于这个特性，如果想搭建一个能够允许 N 台机器 down 掉的集群，
那么就要部署一个由 2*N*+1 台服务器构成的 ZooKeeper 集群。因此，一个由 3 台机器构成的 ZooKeeper 集群，能够在挂掉 1 台机器后依然正常工作，而对于一个由 5 台服务器构成的 ZooKeeper 集群，
能够对 2 台机器挂掉的情况进行容灾。注意，如果是一个由6台服务器构成的 ZooKeeper 集群，同样只能够挂掉 2 台机器，因为如果挂掉 3 台，剩下的机器就无法实现过半了。
因此，从上面的讲解中，我们其实可以看出，**对于一个由 6 台机器构成的 ZooKeeper 集群来说，和一个由 5 台机器构成的 ZooKeeper 集群，其在容灾能力上并没有任何显著的优势，
反而多占用了一个服务器资源**。基于这个原因，ZooKeeper 集群通常设计部署成奇数台服务器即可。

## 18. zk节点宕机如何处理？
Zookeeper 本身也是集群，推荐配置不少于 3 个服务器。Zookeeper 自身也要保证当一个节点宕机时，其他节点会继续提供服务。**Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制**，来检测机器的存活状态。  
如果是一个 Follower 宕机，还有 2 台服务器提供访问，因为 Zookeeper 上的数据是有多个副本的，数据并不会丢失；  
如果是一个 Leader 宕机，Zookeeper 会选举出新的 Leader；  
ZK 集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在 ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。  

## 19. 分布式集群中为什么会有 Master主节点？
在分布式环境中，**有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果**，这样可以大大减少重复计算，提高性能，于是就需要进行 leader 选举。

## 20. chubby 是什么，和 zookeeper 比你怎么看？
chubby 是 google 的，完全实现 paxos 算法，不开源。zookeeper 是 chubby的开源实现，使用 zab 协议，paxos 算法的变种。

## 21. zookeeper leader选举的流程？
zookeeper启动时会同时开启**2888和3888两个端口，前一个端口是leader和follower之间通信的端口，后者是leader选举的端口**;
* **拥有集群中所有机器最高编号（即ZXID最大）的事务Proposal**,那么就可以保证这个新选举出来的Leader一定具有所有已经提交的提案；
* zxId相同时，myid（机器序号）大的成为leader；

### Leader选举实现细节
#### 1、服务器状态
服务器具有四种状态，分别是LOOKING、FOLLOWING、LEADING、OBSERVING。
* LOOKING：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入Leader选举状态。
* FOLLOWING：跟随者状态。表明当前服务器角色是Follower。
* LEADING：领导者状态。表明当前服务器角色是Leader。
* OBSERVING：观察者状态。表明当前服务器角色是Observer。
  
#### 2、投票数据结构
每个投票中包含了两个最基本的信息，所推举服务器的SID和ZXID，投票（Vote）在Zookeeper中包含字段如下。  
* id：被推举的Leader的SID。
* zxid：被推举的Leader事务ID。
* electionEpoch：逻辑时钟，用来判断多个投票是否在同一轮选举周期中，该值在服务端是一个自增序列，每次进入新一轮的投票后，都会对该值进行加1操作。
* peerEpoch：被推举的Leader的epoch。
* state：当前服务器的状态。

Leader选举有如下两种:  
* 第一种：服务器初始化启动的Leader选举。
* 第二种：服务器运行时期的Leader选举（服务器运行期间无法和Leader保持连接）。

#### Leader选举的前提条件
* 只有服务器状态在LOOKING（竞选状态）状态才会去执行选举算法。
* Zookeeper 的集群规模至少是2台机器，才可以选举Leader，这里以3台机器集群为例。
* 当一台服务器启动是不能选举的，等第二台服务器启动后，两台机器之间可以互相通信，才可以进行Leader选举
* 服务器运行期间无法和Leader保持连接的时候。

#### 服务器启动时期的 Leader 选举
在集群初始化阶段，当有一台服务器Server1启动时，其单独无法进行和完成Leader选举，当第二台服务器Server2启动后，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。

选举过程如下：  
(1) **每个Server发出一个投票投给自己****
接受来自各个服务器的投票**。由于是初始情况，Server1和Server2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，
此时Server1的投票为(1, 0)，Server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。  
(2) **接受来自各个服务器的投票**。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。  
(3) **处理投票**。针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下: 
> **优先检查ZXID。ZXID比较大的服务器优先作为Leader。  
如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。**  
对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时Server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，
对于Server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。

(4) **统计投票**。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。  
(5) **改变服务器状态**。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。

#### 服务器运行时期的 Leader 选举
在Zookeeper运行期间，即便当有非Leader服务器宕机或新加入，此时也不会影响Leader，但是**一旦Leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮Leader选举**，其过程和启动时期的Leader选举过程基本一致。
假设正在运行的有Server1、Server2、Server3三台服务器，当前Leader是Server2，若某一时刻Leader挂了，此时便开始Leader选举。选举过程如下：  
(1)**变更状态**。Leader挂后，余下的非Observer服务器都会将自己的服务器状态变更为LOOKING，然后开始进入Leader选举流程。  
(2)**每个Server会发出一个投票**。在这个过程中，需要生成投票信息(myid,ZXID)每个服务器上的ZXID可能不同，我们假定Server1的ZXID为123，而Server3的ZXID为122；在第一轮投票中，Server1和Server3都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。  
(3)**接收来自各个服务器的投票**。与启动时过程相同。  
(4)**处理投票**。与启动时过程相同，此时，Server1将会成为Leader。  
(5)**统计投票**。与启动时过程相同。  
(6)**改变服务器的状态**。与启动时过程相同。  

![vote](https://img2018.cnblogs.com/blog/1708987/201906/1708987-20190608231027312-807663468.png)

来自 <https://www.cnblogs.com/veblen/p/10992103.html> 
