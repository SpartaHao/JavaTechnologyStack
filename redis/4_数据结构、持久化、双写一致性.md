## 22. Redis的常见数据类型？底层是怎么实现的？

### String——字符串
String 数据结构是简单的 key-value 类型，value 不仅可以是 String，也可以是数字（当数字类型用 Long 可以表示的时候encoding 就是整型，其他都存储在 sdshdr 当做字符串）。使用 Strings 类型，可以完全实现目前 Memcached 的功能，并且效率更高。还可以享受 Redis 的定时持久化（可以选择 RDB 模式或者 AOF 模式），操作日志及 Replication 等功能；

> string 类型是二进制安全的。意思是 **redis 的 string 可以包含任何数据**。比如jpg图片或者序列化的对象。

> string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。**底层是sds**；

### Hash——字典
结构化数据，hash 特别适合用于存储对象。每个 hash 可以存储 232 -1 键值对（40多亿）。
> Redis 的 Hash 结构可以使你像在数据库中 Update 一个属性一样只修改某一项属性值。

> 存储、读取、修改用户属性

### List——列表
List 说白了就是链表（redis 使用双端链表实现的 List），一般用来存储列表型的数据结构，类似粉丝列表、文章的评论列表等。

使用 List 可以轻松地实现最新消息排行等功能（比如新浪微博的 TimeLine ）。List 的另一个应用就是**消息队列**，可以利用 List 的 *PUSH 操作，将任务存在 List 中，然后工作线程再用 POP 操作将任务取出进行执行。Redis 还提供了操作 List 中某一段元素的 API，你可以直接查询，删除 List 中某一段的元素。

### Set——集合
集合（set）最大的优势在于可以进行**交集并集差集**操作, 可以非常方便的实现如共同关注、共同喜好、二度好友等功能。Set可包含的最大元素数量是 2^32 -1。

**集合是通过哈希表实现**的，所以添加，删除，查找的复杂度都是O(1)。

应用场景：
* 利用交集求共同好友。
* 利用唯一性，可以统计访问网站的所有独立IP。
* 好友推荐的时候根据tag求交集，大于某个threshold（临界值的）就可以推荐。

### Sorted Set——有序集合
和Sets相比，Sorted Sets是将 Set 中的元素增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列。sorted set是插入有序的，即自动排序。当你需要一个**有序的并且不重复的集合列表**时，那么可以选择sorted set数据结构。

应用举例：
* （1）例如存储全班同学的成绩，其集合value可以是同学的学号，而score就可以是成绩。
* （2）排行榜应用，根据得分列出topN的用户等。

### 底层实现
* 字符串的编码类型  
int：8 个字节的长整型  
embstr：小于等于 39 字节的字符串  
raw：大于 39 字节的字符串  
* 哈希的编码类型  
ziplist：元素个数小于 512，且所有值都小于 64 字节  
hashtable：除上述条件外  
* 列表的编码类型  
ziplist：元素个数小于 512，且所有值都小于 64 字节  
hashtable：除上述条件外  
* 集合的编码类型  
intset：元素个数小于 512，且所有值都是整数  
hashtable：除上述条件外  
* 有序集合的编码类型  
ziplist：元素个数小于 128，且所有值都小于 64 字节  
hashtable：除上述条件外  

参考文献：

https://www.runoob.com/w3cnote/redis-use-scene.html  
https://mp.weixin.qq.com/s?__biz=Mzk0MjE3NDE0Ng==&mid=2247483866&idx=1&sn=d426cb1c3a4f754d560af044b9e00f2c&source=41#wechat_redirect

## 23. 介绍下Redis的SDS的优势？

字符串底层数据结构是 SDS，简单动态字符串  
````
struct sdshdr {
    unsigned int len;
    unsigned int free;
    char buf[];
};
````

1. **常数时间复杂度计算长度**：可以通过 len 直接获取到字符串的长度，而不需要遍历
2. **二进制安全**：由于是**以 len 来表示长度，而不是通过字符串结尾标识来判断**，所以可以用来存储原封不动的二进制数据而不用担心被截断
3. **空间预分配**：在字符串变长时，每次多分配一些空间，以便下次变长时可能由于 buf 足够大而不用重新分配
4. **惰性空间释放**：在字符串变短时，并不立即重新分配内存而回收缩短后多出来的字符串，而是用 free 来记录这些空闲出来的字节，这又减少了内存分配的次数。

参考文献：  
https://my.oschina.net/u/4189097/blog/4840964

## 24. Redis的持久化机制是什么？各自的优缺点？如何选择合适的持久化方式
* 持久化就是把**内存的数据写到磁盘中去（快照）**，防止服务宕机了内存数据丢失。
* redis是内存数据库，如果没有持久化，那么数据断电即失！
* Redis 提供两种持久化机制 **RDB**（默认） 和 **AOF** 机制。
### RDB
RDB是Redis DataBase缩写，快照。RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。


优点：
1. 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。
1. 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。
1. 性能最大化，**fork 子进程来完成写操作，让主进程继续处理命令**，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能。fork子进程，由操作系统进程隔离的特性保证时点性（不会直接从内存拷贝到硬盘，避免IO操作，同时利用操作系统写时复制原理**CopyOnWrite**来保证效率（不会立刻拷贝内存数据到子进程，仅仅是拷贝了一份映射关系，让他们暂时指向同一个内存空间，当父子进程对这块内存空间进行写操作时，才会真正的复制内存，相当于一种延后操作的思想），减少客户端阻塞的时间，可参考低并发编程的文章。
1. 相对于数据集大时，比 AOF 的启动效率更高。

缺点：
1. 数据安全性低。**RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，最后一次修改的数据就没有了**。所以这种方式更适合数据要求不严谨的时候
1. **fork子进程的时候，会对主进程产生阻塞**。如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。

触发机制：
* save的规则满足的情况下，会自动触发rdb规则
> ###RDB持久化配置###

> save 900 1 # 900s内至少一次写操作则执行bgsave进行RDB持久化

> save 300 10

> save 60 10000 

* 执行flushall命令，也会触发我们的rdb规则
* 退出redis，也会产生rdb文件

如何恢复rdb文件？

只需要将rdb文件放到我们redis启动目录就可以，redis启动的时候会自动检查dump.rdb恢复其中的数据！

### AOF
AOF持久化(即**Append Only File**持久化)，则是将Redis执行的**每次写命令记录到单独的日志文件**中（通过write函数追加到appendonly.aof中），当重启Redis会重新将持久化的日志中文件恢复数据。
当两种方式同时开启时，数据恢复**Redis会优先选择AOF恢复**。

优点：
1. 该机制可以带来**更高的数据安全性**，即数据持久性。Redis中提供了3中同步策略，即**每秒同步、每修改同步和不同步**（配置 appendfsync 属性）。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。
1. 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。
1. AOF 机制的 **rewrite 模式**。rewrite会帮我们把过程化的数据干掉，只保留最终的状态数据（如执行set name wh;set name ljj;set name love;rewrite后只会写set name love,进而降低日志大小）。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)

缺点：
1. AOF 文件远大于 RDB 文件，且恢复速度慢。
1. aof运行效率也要比rdb慢，所以我们redis默认的配置就是rdb持久化

### 两者的优缺点是什么？
1. AOF文件比RDB更新频率高，优先使用AOF还原数据。
1. AOF比RDB更安全也更大
1. RDB性能比AOF好
1. 如果两个都配了优先加载AOF

> * 一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。
> * 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。AOF将Redis执行的每一条命令追加到磁盘中，处理巨大的写入会降低Redis的性能，不知道你是否可以接受。
> * 有很多用户都只使用AOF持久化，但并不推荐这种方式，因为**定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快**，除此之外，使用RDB还可以避免AOF程序的bug。
> * 如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。不过生产环境其实更多都是二者结合使用的。

参考文献：

 <https://zhuanlan.zhihu.com/p/222912809> 


## 25. RDB的过程中是否会停止对外提供服务？RDB的过程中数据修改了，备份的是修改前的还是修改后的？RDB时是不是先把内容中的所有KV复制一份，保证数据不会被修改？
1. RDB过程中会fork一个子进程，子进程做数据备份操作，主进程继续对外提供服务，所有Redis服务不会阻塞；
1. Copy On Write 机制，备份的是开始那个时刻内存中的数据；
1. Copy On Write 机制不需要把整个内存的数据都复制一份；

### Copy On Write 机制
核心思路：fork一个子进程，只有在父进程发生写操作修改内存数据时，才会真正去分配内存空间，并复制内存数据，而且也只是复制被修改的内存页中的数据，并不是全部内存数据；
* Redis中执行BGSAVE命令生成RDB文件时，本质就是调用Linux中的fork()命令，**Linux下的fork()系统调用实现了copy-on-write写时复制**；
* fork()是类Unix操作系统上创建线程的主要方法，**fork用于创建子进程**（等同于当前进程的副本）；
* 传统的普通进程复制，会直接将父进程的数据拷贝到子进程中，拷贝完成后，父进程和子进程之间的数据段和堆栈是相互独立的；copy-on-write技术，**在fork出子进程后，父子进程会共享相同的物理内存页，当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作，而子进程依然读取 fork 时整个父进程的内存快照。两者只是虚拟空间不同，但是其对应的物理空间是同一个**；


### Linux中CopyOnWrite实现原理
fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。

### CopyOnWrite的好处：
1. 减少分配和复制资源时带来的瞬时延迟,写时复制是一种延后思想；
1. 减少不必要的资源分配；

### CopyOnWrite的缺点：
1、如果父子进程都需要进行大量的写操作，会产生大量的分页错误（页异常中断page-fault）;

## 26. Redis持久化数据和缓存怎么做扩容？
1. 如果Redis被当做缓存使用（存热点数据），使用一致性哈希实现动态扩容缩容。

1. 如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。

## 27. 如何保证缓存与数据库双写时的数据一致性？
双写一致性指的是，当我们更新了mysql中的数据后也可以同时保证redis中的数据同步更新；

这里肯定不能使用spring 的@Transactional，因为控制事务的话必须要是同一个数据源。

一般来说有以下四种场景：
### 先更新缓存，在更新数据库
如果redis更新成功，mysql更新失败，这时造成redis脏数据问题，这种策略是绝对不能使用的。

### 先更新数据库，在更新缓存
这套方案，大家是普遍反对的。为什么呢？有如下两点原因。

原因一（**线程安全角度**） 同时有请求A和请求B进行更新操作，那么会出现：

1. 线程A更新了数据库
1. 线程B更新了数据库
1. 线程B更新了缓存
1. 线程A更新了缓存

请求A更新缓存应该比请求B更新缓存早，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，造成ThreadB对缓存的更新丢失，这是一个很严重的问题，因此不考虑

原因二（**业务场景角度**） 有如下两点：

1. 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，**数据压根还没读到，缓存就被频繁的更新，浪费性能（懒加载的思想比较好）**。
1. 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。
### 先删除缓存，再更新数据库
该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

* （1）请求A进行写操作，删除缓存
* （2）请求B查询发现缓存不存在
* （3）请求B去数据库查询得到旧值
* （4）请求B将旧值写入缓存
* （5）请求A将新值写入数据库 上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

那么，如何解决呢？采用**延时双删策略** 伪代码如下

`public void write(String key,Object data){`

        `redis.delKey(key);`

        `db.updateData(data);`

        `Thread.sleep(1000);`

        `redis.delKey(key);`
    `}`

转化为中文描述就是

* （1）先淘汰缓存
* （2）再写数据库（这两步和原来一样）
* （3）休眠1秒，再次淘汰缓存 这么做，可以将1秒内所造成的缓存脏数据，再次删除。

那么，**这个1秒怎么确定的，具体该休眠多久呢？**

针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

## 先更新数据库，再删缓存
即**Cache Aside Pattern，最经典的缓存+数据库读写的模式**
* 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
* 更新的时候，先更新数据库，然后再删除缓存。

这种情况下也会有并发问题。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：
* （1）缓存刚好失效
* （2）请求A查询数据库，得一个旧值
* （3）请求B将新值写入数据库
* （4）请求B删除缓存
* （5）请求A将查到的旧值写入缓存 ok，如果发生上述情况，确实是会发生脏数据。

但是出现这种情况的概率极低，因为数据库的读操作的速度远快于写操作的，因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。即使有，也同样可以使用异步延时双删的策略。

### 如果采用延时双删策略，第二次删除缓存失败怎么办？
提供一个保障的重试机制即可。流程如下图所示：

* （1）更新数据库数据
* （2）数据库会将操作信息写入binlog日志当中
* （3）订阅程序提取出所需要的数据以及key
* （4）另起一段非业务代码，获得该信息
* （5）尝试删除缓存操作，发现删除失败
* （6）将这些信息发送至消息队列
* （7）重新从消息队列中获得该数据，重试操作。

备注说明：上述的**订阅binlog程序在mysql中有现成的中间件叫canal**，可以完成订阅binlog日志的功能。

### 实际系统的解决方案
延时双删在加消息队列加canal的方式太复杂了，一般如果系统不是要求强一致性的话，**给缓存设置过期时间就可以了，保证最终一致性**。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

我们的系统不是严格要求 “缓存+数据库”强一致性的，因为我们的整个任务执行是一个长事务，对时效性要求的不是很严格，比方说任务执行进度，和执行结果即使晚几秒在更新也没什么关系，只要保证最终一致性，即任务结束时，查询是ok的就行了。我们使用了二级缓存，google的LoadingCache(Guava Cache)和redission，然后根据数据的变更速度，分了三个等级，300ms，1s和5s。但是本地缓存其实是没生效的，因为两级缓存的过期时间设置的是一样的，同时缓存没有读到，读数据库，更新缓存时也没有更新到本地缓存。给面试官描述的时候可以只说用了redission缓存，避免不必要的麻烦。这里使用本地缓存应该也是为了利用guava cache会严格限制只有1个加载操作，这样会很好地防止缓存失效的瞬间大量请求穿透到后端引起雪崩效应。

还是要结合业务区考虑，找到适合自己的方案。**即使对于失效性要求比较高的订单系统，也是通过对缓存key设置一个过期时间实现的**，因为查看系统库存到真正提交订单修改数据库中的库存数据，是需要一定的时间的，这个时间段内库存本来就是有可能变化的，所以不一定要求缓存和数据库的库存数据严格一致。

参考文件：

https://zhuanlan.zhihu.com/p/59167071

https://blog.csdn.net/weixin_41251135/article/details/109964085

## 28. 之前常用 ConcurrentMap来做本地缓存，Guava Cache对比有什么区别呢？两者和redis有什么区别？
最基本的区别是**ConcurrentMap会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache为了限制内存占用，通常都设定为自动回收元素，可设置过期时间**。同时可以灵活的设置过期策略。

三种基于时间的清理或刷新缓存数据的方式：
* expireAfterAccess: 当缓存项在指定的时间段内没有被读或写就会被回收。
* expireAfterWrite：当缓存项在指定的时间段内没有更新就会被回收。
* refreshAfterWrite：当缓存项上一次更新操作之后的多久会被刷新。
考虑到时效性，我们可以使用expireAfterWrite，使每次更新之后的指定时间让缓存失效，然后重新加载缓存。**guava cache会严格限制只有1个加载操作，这样会很好地防止缓存失效的瞬间大量请求穿透到后端引起雪崩效应**。
Ø Guava Cache和Map是单个应用运行时的本地缓存，**单机版的缓存，它不把数据存放到文件或外部服务器。而redis是中央缓存，所有的分布式服务都可以从redis取到相同的数据**。

## 29. 说说Redis哈希槽的概念？
Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。
